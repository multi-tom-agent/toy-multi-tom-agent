{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCooperative Gridworld — Trust, Sabotage, and ToM (v1)\\n-----------------------------------------------------\\nThis file implements a tiny, fully observable \"wheat-and-bread\" gridworld\\ndesigned for studying *language-based multi-agent cooperation*, *adversarial\\nsabotage*, and *theory-of-mind (ToM) trust adaptation*.\\n\\nThe world has:\\n- two agents sharing a single crafting station,\\n- scattered wheat tiles as a limited common resource,\\n- a simple recipe (WHEAT → BREAD),\\n- and a uniform protocol where every policy outputs {\"message\", \"action\"}.\\n\\nOn top of this minimal environment, we plug in different roles and policies:\\n- **CooperativePolicy**: tries to share wheat and coordinate handoffs to craft.\\n- **AdversarialPolicy**: hoards wheat, denies access, and kites away.\\n- **TheoryOfMindPolicy**: maintains a scalar trust belief over the teammate and\\n  switches between cooperative / self-reliant strategies based on observed chat\\n  and actions.\\n\\nResearch goals\\n--------------\\n- Provide a *small but non-trivial* testbed for:\\n  (a) cooperation under shared resource constraints,\\n  (b) adversarial interference, and\\n  (c) ToM-style trust calibration from text + actions.\\n- Make reasoning *inspectable*: policies communicate via short natural-language\\n  messages, and all decisions are logged turn-by-turn for analysis.\\n- Serve as a modular scaffold where more complex observation shaping, reward\\n  structures, and policies (e.g. LLM-based) can be dropped in without touching\\n  the core environment.\\n\\nBroader impact\\n--------------\\nAlthough toy, this gridworld is intended as a sandbox for *verifiable safety in\\nmulti-agent collaboration*. It highlights how:\\n- language can be used both to *coordinate* and to *mislead*,\\n- trust estimates can drift under sabotage or misuse of communication, and\\n- simple, transparent environments can expose coordination failures that are\\n  hard to see in large, opaque systems.\\n\\nPatterns studied here (resource hoarding, denial of service, brittle trust\\nupdates) appear in more realistic domains such as warehouse robotics, supply\\nchains, and online collaborative tools. By keeping the setup minimal and fully\\nlogged, the project aims to make these safety questions easier to prototype,\\nvisualize, and teach.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Cooperative Gridworld — Trust, Sabotage, and ToM (v1)\n",
    "-----------------------------------------------------\n",
    "This file implements a tiny, fully observable \"wheat-and-bread\" gridworld\n",
    "designed for studying *language-based multi-agent cooperation*, *adversarial\n",
    "sabotage*, and *theory-of-mind (ToM) trust adaptation*.\n",
    "\n",
    "The world has:\n",
    "- two agents sharing a single crafting station,\n",
    "- scattered wheat tiles as a limited common resource,\n",
    "- a simple recipe (WHEAT → BREAD),\n",
    "- and a uniform protocol where every policy outputs {\"message\", \"action\"}.\n",
    "\n",
    "On top of this minimal environment, we plug in different roles and policies:\n",
    "- **CooperativePolicy**: tries to share wheat and coordinate handoffs to craft.\n",
    "- **AdversarialPolicy**: hoards wheat, denies access, and kites away.\n",
    "- **TheoryOfMindPolicy**: maintains a scalar trust belief over the teammate and\n",
    "  switches between cooperative / self-reliant strategies based on observed chat\n",
    "  and actions.\n",
    "\n",
    "Research goals\n",
    "--------------\n",
    "- Provide a *small but non-trivial* testbed for:\n",
    "  (a) cooperation under shared resource constraints,\n",
    "  (b) adversarial interference, and\n",
    "  (c) ToM-style trust calibration from text + actions.\n",
    "- Make reasoning *inspectable*: policies communicate via short natural-language\n",
    "  messages, and all decisions are logged turn-by-turn for analysis.\n",
    "- Serve as a modular scaffold where more complex observation shaping, reward\n",
    "  structures, and policies (e.g. LLM-based) can be dropped in without touching\n",
    "  the core environment.\n",
    "\n",
    "Broader impact\n",
    "--------------\n",
    "Although toy, this gridworld is intended as a sandbox for *verifiable safety in\n",
    "multi-agent collaboration*. It highlights how:\n",
    "- language can be used both to *coordinate* and to *mislead*,\n",
    "- trust estimates can drift under sabotage or misuse of communication, and\n",
    "- simple, transparent environments can expose coordination failures that are\n",
    "  hard to see in large, opaque systems.\n",
    "\n",
    "Patterns studied here (resource hoarding, denial of service, brittle trust\n",
    "updates) appear in more realistic domains such as warehouse robotics, supply\n",
    "chains, and online collaborative tools. By keeping the setup minimal and fully\n",
    "logged, the project aims to make these safety questions easier to prototype,\n",
    "visualize, and teach.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import argparse, dataclasses, json, random\n",
    "from enum import Enum, auto\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import random\n",
    "from typing import Tuple, Optional, List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. World Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Agent and Game State Structs\n",
    "> - `Pos` represents a **grid position** with:\n",
    ">   - `manhattan()` for standard L1 distance, and  \n",
    ">   - `adjacent()` using Chebyshev distance (≤ 1 means “adjacent”, including diagonals).\n",
    "> - `AgentState` stores the **environment-side state** of a single agent:\n",
    ">   - its name (`\"ALICE\"` / `\"BOB\"`),\n",
    ">   - current position, and\n",
    ">   - inventory as a list of item strings.\n",
    "> - `GameState` is a **snapshot of the whole world** used to build policy inputs:\n",
    ">   - the grid layout,\n",
    ">   - all agents’ states,\n",
    ">   - how many goal items have been crafted,\n",
    ">   - the current turn number,\n",
    ">   - recent chat messages,\n",
    ">   - the station position, and\n",
    ">   - the last actions (intents) taken by each agent.\n",
    ">\n",
    "> ### GridWorld: Map and Resource Layout\n",
    "> - `GridWorld` manages the **static grid map** and resource placement:\n",
    ">   - creates an `size × size` grid of empty tiles,\n",
    ">   - randomly places **one crafting station**,\n",
    ">   - then scatters wheat tiles across random empty cells.\n",
    "> - `_random_empty()` samples a random empty position to place new objects without collisions.\n",
    "> - `in_bounds()` checks if a position stays inside the grid.\n",
    "> - `as_text()` renders a simple **ASCII view** of the grid, overlaying agent initials on their current cells for debugging and logging.\n",
    ">\n",
    "> ### Roles and Primitive Actions\n",
    "> - `Role` is a small enum that labels the **intended behavior type** of a policy:\n",
    ">   - `COOP` for cooperative agents,\n",
    ">   - `ADVERSARY` for agents that try to sabotage.\n",
    "> - `MOVE_DELTAS` defines the **four directional moves** as row/column offsets.\n",
    "> - `VALID_ACTIONS` lists all **primitive actions** the environment understands:\n",
    ">   moving, picking wheat, crafting bread, dropping wheat back on the ground,\n",
    ">   giving wheat to a teammate, or waiting.\n",
    ">\n",
    "> ### CoopGame: Environment Core and Turn Logic\n",
    "> - `CoopGame` ties everything together:\n",
    ">   - owns a `GridWorld` instance,\n",
    ">   - creates two agents (`ALICE` and `BOB`) at random positions,\n",
    ">   - tracks per-agent inventory capacity, the current goal (`BREAD`),\n",
    ">   - how many goal items have been crafted, the current turn, chat history,\n",
    ">   - and the last actions chosen by each agent.\n",
    "> - `snapshot()` returns a **read-only copy** of the current state so policies\n",
    ">   can reason without mutating the environment.\n",
    "> - `step(intents)` advances the world by one turn in two phases:\n",
    ">   1. **Move phase:** apply any `MOVE_*` actions if they stay inside the grid.\n",
    ">   2. **Interact phase:** resolve `PICK`, `CRAFT`, `DROP`, and `GIVE`:\n",
    ">      - `PICK`: convert a wheat tile under the agent into `ITEM_WHEAT` in inventory.\n",
    ">      - `CRAFT`: if at the station with enough wheat, consume it and increment the crafted bread counter.\n",
    ">      - `DROP`: turn one `ITEM_WHEAT` back into a wheat tile on an empty cell.\n",
    ">      - `GIVE`: transfer one `ITEM_WHEAT` to the teammate if adjacent and they have space.\n",
    ">   After applying interactions, it increments the turn counter and records the last intents for use by ToM-style policies.\n",
    "> - `is_done()` checks whether the **episode has succeeded** (at least one bread crafted).\n",
    "> - `render_text()` provides a simple textual visualization of the current grid and agent positions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Tiles, Items, Recipe ======\n",
    "# Simple symbolic encoding for the grid.\n",
    "TILE_EMPTY = \".\"\n",
    "TILE_WHEAT = \"W\"\n",
    "TILE_STATION = \"C\"\n",
    "\n",
    "# Logical item names used in inventories.\n",
    "ITEM_WHEAT = \"WHEAT\"\n",
    "ITEM_BREAD = \"BREAD\"\n",
    "\n",
    "# Minimal recipe: 1 BREAD requires 5 WHEAT.\n",
    "RECIPE = {ITEM_BREAD: {ITEM_WHEAT: 5}}\n",
    "\n",
    "# ====== Agent, Game States ======\n",
    "@dataclasses.dataclass(frozen=True)\n",
    "class Pos:\n",
    "    \"\"\"Grid position (row, col) with basic distance helpers.\"\"\"\n",
    "    r: int\n",
    "    c: int\n",
    "    def manhattan(self, other: \"Pos\") -> int:\n",
    "        return abs(self.r - other.r) + abs(self.c - other.c)\n",
    "    def adjacent(self, other: \"Pos\") -> int:\n",
    "        \"\"\"Adjacent if max(|dr|, |dc|) ≤ 1 — includes diagonals.\"\"\"\n",
    "        return max(abs(self.r - other.r), abs(self.c - other.c))\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class AgentState:\n",
    "    \"\"\"Environment-side state of an agent.\"\"\"\n",
    "    name: str\n",
    "    pos: Pos\n",
    "    inv: List[str]\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class GameState:\n",
    "    \"\"\"Snapshot of the environment state used to build Belief for policies.\"\"\"\n",
    "    grid: List[List[str]]\n",
    "    agents: Dict[str, AgentState]\n",
    "    crafted: Dict[str, int]\n",
    "    turn: int\n",
    "    chat_log: List[Tuple[str,str]]\n",
    "    station: Pos\n",
    "    last_intents: Dict[str,str]\n",
    "\n",
    "# ====== Grid World ======\n",
    "class GridWorld:\n",
    "    \"\"\"Grid-world with a single crafting station and scattered wheat tiles.\"\"\"\n",
    "    def __init__(self, size: int = 6, seed: int = 0, wheat_count: Optional[int] = None):\n",
    "        random.seed(seed)\n",
    "        self.size = size\n",
    "        self.grid = [[TILE_EMPTY for _ in range(size)] for _ in range(size)]\n",
    "        # Place crafting station.\n",
    "        self.station = self._random_empty()\n",
    "        self.grid[self.station.r][self.station.c] = TILE_STATION\n",
    "        # Place wheat tiles.\n",
    "        if wheat_count is None:\n",
    "            wheat_count = max(4, size)\n",
    "        for _ in range(wheat_count):\n",
    "            p = self._random_empty()\n",
    "            self.grid[p.r][p.c] = TILE_WHEAT\n",
    "\n",
    "    def _random_empty(self) -> Pos:\n",
    "        \"\"\"Sample a random empty cell.\"\"\"\n",
    "        while True:\n",
    "            r = random.randrange(self.size); c = random.randrange(self.size)\n",
    "            if self.grid[r][c] == TILE_EMPTY:\n",
    "                return Pos(r, c)\n",
    "\n",
    "    def in_bounds(self, p: Pos) -> bool:\n",
    "        \"\"\"Check if position lies inside the grid.\"\"\"\n",
    "        return 0 <= p.r < self.size and 0 <= p.c < self.size\n",
    "\n",
    "    def as_text(self, agents: Dict[str, AgentState]) -> str:\n",
    "        \"\"\"ASCII view of grid with agent initials rendered on top.\"\"\"\n",
    "        g = [row[:] for row in self.grid]\n",
    "        for a in agents.values():\n",
    "            g[a.pos.r][a.pos.c] = a.name[0]\n",
    "        return \"\\n\".join(\" \".join(row) for row in g)\n",
    "\n",
    "# ====== Policy ======\n",
    "class Role(Enum):\n",
    "    \"\"\"High-level role, used to branch behavior in policies.\"\"\"\n",
    "    COOP = auto()\n",
    "    ADVERSARY = auto()\n",
    "\n",
    "# Primitive actions supported by the environment.\n",
    "MOVE_DELTAS = {\n",
    "    \"MOVE_N\":(-1,0),\n",
    "    \"MOVE_S\":(1,0),\n",
    "    \"MOVE_W\":(0,-1),\n",
    "    \"MOVE_E\":(0,1),\n",
    "}\n",
    "VALID_ACTIONS = set(list(MOVE_DELTAS.keys()) + [\"PICK\",\"CRAFT\",\"DROP\",\"GIVE\",\"WAIT\"])\n",
    "\n",
    "# ====== Game Core ======\n",
    "class CoopGame:\n",
    "    \"\"\"\n",
    "    Environment core: owns GridWorld, agent states, crafting state, and chat log.\n",
    "    \"\"\"\n",
    "    def __init__(self, size: int = 6, seed: int = 0):\n",
    "        self.world = GridWorld(size=size, seed=seed)\n",
    "        a1 = self.world._random_empty(); a2 = self.world._random_empty()\n",
    "        self.agents: Dict[str,AgentState] = {\n",
    "            \"ALICE\": AgentState(\"ALICE\", a1, []),\n",
    "            \"BOB\":   AgentState(\"BOB\",   a2, []),\n",
    "        }\n",
    "        self.capacity: Dict[str, int] = {\"ALICE\": 10, \"BOB\": 10}  # will be set from roster\n",
    "        self.goal = ITEM_BREAD\n",
    "        self.crafted = {ITEM_BREAD: 0}\n",
    "        self.turn = 0\n",
    "        self.chat_log: List[Tuple[str,str]] = []\n",
    "        self.last_intents: Dict[str,str] = {}\n",
    "\n",
    "    @property\n",
    "    def station(self) -> Pos:\n",
    "        return self.world.station\n",
    "\n",
    "    def snapshot(self) -> GameState:\n",
    "        \"\"\"Take a read-only snapshot of current env state for policies.\"\"\"\n",
    "        return GameState(\n",
    "            grid=[row[:] for row in self.world.grid],\n",
    "            agents={k: dataclasses.replace(v) for k,v in self.agents.items()},\n",
    "            crafted=self.crafted.copy(),\n",
    "            turn=self.turn,\n",
    "            chat_log=self.chat_log[:],\n",
    "            station=self.station,\n",
    "            last_intents=self.last_intents.copy(),\n",
    "        )\n",
    "\n",
    "    def step(self, intents: Dict[str,str]):\n",
    "        \"\"\"\n",
    "        Advance environment by one turn.\n",
    "\n",
    "        Two-phase update:\n",
    "        1) Move phase: apply MOVE_* actions.\n",
    "        2) Interact phase: PICK / CRAFT / DROP / GIVE are resolved.\n",
    "\n",
    "        Also updates last_intents for ToM reasoning.\n",
    "        \"\"\"\n",
    "        # move phase ...\n",
    "        for name, a in self.agents.items():\n",
    "            act = intents.get(name, \"WAIT\")\n",
    "            if act in MOVE_DELTAS:\n",
    "                dr, dc = MOVE_DELTAS[act]\n",
    "                p = Pos(a.pos.r + dr, a.pos.c + dc)\n",
    "                if self.world.in_bounds(p):\n",
    "                    # (Optional) allow passing through each other; block if you want:\n",
    "                    # if any(o.pos == p for n,o in self.agents.items() if n != name): \n",
    "                    #     continue\n",
    "                    a.pos = p\n",
    "                    \n",
    "        # interact phase ...\n",
    "        for name, a in self.agents.items():\n",
    "            act = intents.get(name, \"WAIT\")\n",
    "            if act == \"PICK\":\n",
    "                cap = 10\n",
    "                if self.world.grid[a.pos.r][a.pos.c] == TILE_WHEAT and len(a.inv) < cap:\n",
    "                    a.inv.append(ITEM_WHEAT)\n",
    "                    self.world.grid[a.pos.r][a.pos.c] = TILE_EMPTY\n",
    "            elif act == \"CRAFT\":\n",
    "                if a.pos == self.station:\n",
    "                    need = RECIPE[self.goal][ITEM_WHEAT]\n",
    "                    if a.inv.count(ITEM_WHEAT) >= need:\n",
    "                        for _ in range(need): a.inv.remove(ITEM_WHEAT)\n",
    "                        self.crafted[self.goal] += 1\n",
    "            elif act == \"DROP\":\n",
    "                # Convert one wheat in inventory back into a wheat tile if cell is empty.\n",
    "                if ITEM_WHEAT in a.inv and self.world.grid[a.pos.r][a.pos.c] == TILE_EMPTY:\n",
    "                    a.inv.remove(ITEM_WHEAT)\n",
    "                    self.world.grid[a.pos.r][a.pos.c] = TILE_WHEAT\n",
    "            elif act == \"GIVE\":\n",
    "                # Give one wheat to teammate if adjacent and they have capacity\n",
    "                other_name = \"BOB\" if name == \"ALICE\" else \"ALICE\"\n",
    "                tm = self.agents[other_name]\n",
    "                tm_cap = 10  # could later use self.capacity.get(other_name, 1)\n",
    "                if ITEM_WHEAT in a.inv and len(tm.inv) < tm_cap and a.pos.adjacent(tm.pos) <= 1:\n",
    "                    a.inv.remove(ITEM_WHEAT)\n",
    "                    tm.inv.append(ITEM_WHEAT)\n",
    "        self.turn += 1\n",
    "        self.last_intents = intents.copy()\n",
    "\n",
    "    def is_done(self) -> bool:\n",
    "        \"\"\"Episode terminates once at least one BREAD is crafted.\"\"\"\n",
    "        return self.crafted[self.goal] >= 1\n",
    "\n",
    "    def render_text(self) -> str:\n",
    "        \"\"\"Convenience wrapper for textual grid rendering.\"\"\"\n",
    "        return self.world.as_text(self.agents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Policy Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(1) Base Belief \\& Policy**\n",
    "> ### Belief: What a Policy Sees\n",
    "> The `Belief` dataclass is the **policy’s full observation** for a single turn.  \n",
    "> It includes only the information an agent is allowed to reason over:\n",
    "> - **Game progress:** current turn, the shared crafting goal, and its recipe.\n",
    "> - **Environment state:** the grid layout and station location.\n",
    "> - **Agent states:** the policy’s own state (`self_state`) and the teammate’s state.\n",
    "> - **Communication context:** the most recent chat messages and each agent’s last chosen intent.\n",
    "> - **Constraints:** the inventory capacity the policy should respect.\n",
    ">\n",
    "> Policies treat this as their *single source of truth* when generating messages and actions.\n",
    "\n",
    "> ### BasePolicy: Interface for All Agent Behaviors\n",
    "> `BasePolicy` is the abstract parent class for every agent behavior (Cooperative, Adversarial, ToM):\n",
    "> - Each policy has a **name** and a **role** (`COOP` or `ADVERSARY`).\n",
    "> - The key method is `act(belief) → (message, action)`, which:\n",
    ">   - receives a `Belief` object,\n",
    ">   - outputs a short natural-language message and one environment action.\n",
    "> - Subclasses must override `act()` to define their decision logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class Belief:\n",
    "    \"\"\"\n",
    "    Structured observation passed into policies.\n",
    "\n",
    "    This bundles everything the policy is allowed to know:\n",
    "    - static map (grid, station)\n",
    "    - current turn & goal\n",
    "    - self / teammate local state\n",
    "    - last chat messages and last high-level intents\n",
    "    \"\"\"\n",
    "    turn: int\n",
    "    goal: str\n",
    "    recipe: Dict[str,int]\n",
    "    station: Pos\n",
    "    grid: List[List[str]]\n",
    "    self_state: AgentState\n",
    "    teammate_state: AgentState\n",
    "    chat_last: List[Tuple[str,str]]\n",
    "    last_intents: Dict[str,str]\n",
    "    inventory_capacity: int = 10\n",
    "\n",
    "class BasePolicy:\n",
    "    \"\"\"Abstract policy interface: takes Belief, returns (chat message, action).\"\"\"\n",
    "    def __init__(self, name: str, role: Role):\n",
    "        self.name = name\n",
    "        self.role = role\n",
    "    def act(self, belief: Belief) -> Tuple[str,str]:\n",
    "        \"\"\"Return (message, action). Must respect VALID_ACTIONS and be short.\"\"\"\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(1) Cooperative Policy**\n",
    "> ### CooperativePolicy: Basic Teamwork Logic\n",
    "> This policy implements a simple cooperative strategy for two agents trying to craft bread together:\n",
    ">\n",
    "> **Core behavior**\n",
    "> - **Solo craft if possible:** If the agent already holds enough wheat, it goes straight to the station.\n",
    "> - **Team handoff:** If the *combined* wheat is enough, the agents try to meet and transfer wheat using `GIVE`.\n",
    "> - **Resource collection:** Otherwise, the agent collects wheat while lightly deconflicting with its teammate (avoiding chasing the same tile when possible).\n",
    ">\n",
    "> **Helper methods**\n",
    "> - `_step_toward(a, b)`: Greedy Chebyshev movement toward a target.\n",
    "> - `_adjacent(a, b)`: Checks whether two agents are in Chebyshev adjacency (including diagonals).\n",
    "> - `_older_name(...)`: Deterministic tie-breaker for deciding which agent should give when both hold wheat.\n",
    ">\n",
    "> **Decision flow**\n",
    "> 1. **Have enough wheat?**  \n",
    ">    → Move to station and `CRAFT`.\n",
    "> 2. **Together have enough wheat?**  \n",
    ">    → Move toward teammate; if adjacent, let the “designated giver” perform `GIVE`.\n",
    "> 3. **Not enough wheat yet?**  \n",
    ">    → Collect the nearest wheat, choosing an alternate tile if the teammate is closer to the same one.\n",
    ">\n",
    "> The output of `act()` is always a pair:  \n",
    "> **(short chat message, environment action)**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CooperativePolicy(BasePolicy):\n",
    "    \"\"\"\n",
    "    Simple cooperative policy:\n",
    "    - First tries to solo craft if it already holds enough wheat.\n",
    "    - Otherwise tries to coordinate a GIVE-based handoff when total wheat is enough.\n",
    "    - If not enough wheat yet, collects wheat with light deconfliction vs teammate.\n",
    "    \"\"\"\n",
    "    def __init__(self, name: str):\n",
    "        super().__init__(name, Role.COOP)\n",
    "        self._adjacent_last: bool = False\n",
    "\n",
    "    def _step_toward(self, a: Pos, b: Pos) -> str:\n",
    "        \"\"\"Greedy move toward target using Chebyshev distance.\"\"\"\n",
    "        dr, dc = b.r - a.r, b.c - a.c\n",
    "        if abs(dr) >= abs(dc) and dr != 0: return \"MOVE_S\" if dr > 0 else \"MOVE_N\"\n",
    "        if dc != 0: return \"MOVE_E\" if dc > 0 else \"MOVE_W\"\n",
    "        return \"WAIT\"\n",
    "\n",
    "    def _adjacent(self, a: Pos, b: Pos) -> bool:\n",
    "        \"\"\"Adjacent if max(|dr|, |dc|) ≤ 1 — includes diagonals.\"\"\"\n",
    "        return max(abs(a.r - b.r), abs(a.c - b.c)) <= 1\n",
    "    \n",
    "    # ---- creation-time priority (older gives); falls back to lexicographic if unknown ----\n",
    "    def _creation_turn(self, belief: Belief, agent_name: str) -> int:\n",
    "        \"\"\"\n",
    "        Optional hook: look up creation/birth turn in belief for tie-breaking.\n",
    "        If unavailable, return INF so that lexicographic fallback is used.\n",
    "        \"\"\"\n",
    "        INF = 10**9\n",
    "        if hasattr(belief, \"birth_turns\") and agent_name in belief.birth_turns:\n",
    "            return belief.birth_turns[agent_name]\n",
    "        if hasattr(belief, \"spawn_turns\") and agent_name in belief.spawn_turns:\n",
    "            return belief.spawn_turns[agent_name]\n",
    "        if hasattr(belief, \"created_at\") and agent_name in belief.created_at:\n",
    "            return belief.created_at[agent_name]\n",
    "        return INF\n",
    "\n",
    "    def _older_name(self, belief: Belief, a: str, b: str) -> str:\n",
    "        \"\"\"\n",
    "        Deterministic tiebreaker: conceptually, older agent should give.\n",
    "        Currently falls back to lexicographic ordering for determinism.\n",
    "        \"\"\"\n",
    "        # ta, tb = self._creation_turn(belief, a), self._creation_turn(belief, b)\n",
    "        # if ta != tb:\n",
    "        #     return a if ta < tb else b\n",
    "        return b if a < b else a  # deterministic tiebreak\n",
    "\n",
    "    def act(self, belief: Belief) -> Tuple[str, str]:\n",
    "        \"\"\"High-level cooperative decision logic.\"\"\"\n",
    "        me, tm = belief.self_state, belief.teammate_state\n",
    "        inv = list(me.inv); inv_w = inv.count(ITEM_WHEAT)\n",
    "        tm_w = tm.inv.count(ITEM_WHEAT)\n",
    "        need_w = RECIPE[ITEM_BREAD][ITEM_WHEAT]\n",
    "        cap = 10\n",
    "\n",
    "        # 1) Solo craft if possible\n",
    "        if inv_w >= need_w:\n",
    "            if me.pos == belief.station: return (\"crafting\", \"CRAFT\")\n",
    "            return (\"to C\", self._step_toward(me.pos, belief.station))\n",
    "\n",
    "        # 2) Team handoff if together sufficient\n",
    "        if inv_w + tm_w >= need_w and (inv_w >= 1 or tm_w >= 1):\n",
    "            if self._adjacent(me.pos, tm.pos):\n",
    "                # A) Exactly one holds wheat → that holder gives (unless receiver is full)\n",
    "                if inv_w >= 1 and tm_w == 0:\n",
    "                    if len(tm.inv) >= cap:      # receiver full, let them go make space\n",
    "                        return (\"recv full→you go C\", \"WAIT\")\n",
    "                    return (\"take mine\", \"GIVE\")  # PLAIN GIVE (env supports it)\n",
    "\n",
    "                if tm_w >= 1 and inv_w == 0:\n",
    "                    if len(inv) >= cap:\n",
    "                        return (\"make space→C\", self._step_toward(me.pos, belief.station))\n",
    "                    return (\"ready\", \"WAIT\")\n",
    "\n",
    "                # B) Both have ≥1 → older-created gives\n",
    "                elected = self._older_name(belief, me.name, tm.name)\n",
    "                if me.name == elected:\n",
    "                    if len(tm.inv) >= cap:\n",
    "                        return (\"recv full; wait\", \"WAIT\")\n",
    "                    return (\"take mine\", \"GIVE\")  # PLAIN GIVE\n",
    "                else:\n",
    "                    if len(inv) >= cap:\n",
    "                        return (\"make space→C\", self._step_toward(me.pos, belief.station))\n",
    "                    return (\"ready\", \"WAIT\")\n",
    "\n",
    "            # Not adjacent → converge for handoff (don’t overcollect)\n",
    "            return (\"to you\", self._step_toward(me.pos, tm.pos))\n",
    "\n",
    "        # 3) Otherwise collect (light deconfliction)\n",
    "        wheat = [Pos(r,c) for r,row in enumerate(belief.grid) for c,v in enumerate(row) if v == TILE_WHEAT]\n",
    "        if wheat:\n",
    "            near = min(wheat, key=lambda p: p.adjacent(me.pos))\n",
    "            if near == me.pos:\n",
    "                if len(inv) < cap: return (\"pick\", \"PICK\")\n",
    "                if tm_w > 0:       return (\"to you\", self._step_toward(me.pos, tm.pos))\n",
    "                return (\"full→C\", self._step_toward(me.pos, belief.station))\n",
    "            tm_near = min(wheat, key=lambda p: p.adjacent(tm.pos)) if wheat else None\n",
    "            choice = near\n",
    "            if tm_near == near:\n",
    "                alts = sorted(wheat, key=lambda p: p.adjacent(me.pos))\n",
    "                choice = alts[1] if len(alts) > 1 else near\n",
    "            return (\"to W\", self._step_toward(me.pos, choice))\n",
    "\n",
    "        return (\"wait\", \"WAIT\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(2) Adversarial Policy**\n",
    "> ### AdversarialPolicy: Hoarder / Denial-of-Service Agent\n",
    "> This policy implements a **sabotaging teammate** whose goal is to *deny wheat* and *never help*:\n",
    ">\n",
    "> **Core behavior**\n",
    "> - **Deny phase (not full yet):**\n",
    ">   - Finds the wheat tile closest to the *teammate* and rushes toward it.\n",
    ">   - If already standing on that tile, it `PICK`s the wheat.\n",
    "> - **Hoard / kite phase (holding any wheat):**\n",
    ">   - Refuses to `GIVE`, `CRAFT`, or `DROP`.\n",
    ">   - Moves to increase its distance from *both* the station and the teammate, effectively hiding with the resources.\n",
    "> - **No wheat + empty bag:**\n",
    ">   - Still drifts away from the station and teammate, staying unhelpful.\n",
    ">\n",
    "> **Helper method**\n",
    "> - `_best_away_move(...)`: evaluates all local moves and picks the one that **maximizes Chebyshev distance** to the station + teammate, producing the kiting behavior.\n",
    ">\n",
    "> As with other policies, `act()` returns a pair  \n",
    "> **(short chat message, environment action)**, making its sabotage legible in the logs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdversarialPolicy(BasePolicy):\n",
    "    \"\"\"Hoarder adversary:\n",
    "      - If bag not full: rush the wheat closest to the teammate (deny).\n",
    "      - When on wheat: PICK.\n",
    "      - If holding any wheat (or full): NEVER GIVE/CRAFT/DROP. Move to increase\n",
    "        distance from BOTH the station and the teammate (kite to far corners).\"\"\"\n",
    "    def __init__(self, name: str):\n",
    "        super().__init__(name, Role.ADVERSARY)\n",
    "\n",
    "    def _best_away_move(self, world_size: Tuple[int,int], me: Pos, tm: Pos, station: Pos) -> str:\n",
    "        \"\"\"\n",
    "        Greedy one-step search: choose the move that maximizes distance to\n",
    "        both station and teammate (using Chebyshev distance).\n",
    "        \"\"\"\n",
    "        candidates = [(\"WAIT\", (0,0)), (\"MOVE_N\", (-1,0)), (\"MOVE_S\", (1,0)),\n",
    "                      (\"MOVE_W\", (0,-1)), (\"MOVE_E\", (0,1))]\n",
    "        H, W = world_size\n",
    "        best_act, best_score = \"WAIT\", -1e9\n",
    "        for act, (dr,dc) in candidates:\n",
    "            nr, nc = me.r + dr, me.c + dc\n",
    "            if not (0 <= nr < H and 0 <= nc < W):  # stay in-bounds\n",
    "                continue\n",
    "            p = Pos(nr, nc)\n",
    "            score = p.adjacent(station) + p.adjacent(tm)\n",
    "            if score > best_score:\n",
    "                best_score, best_act = score, act\n",
    "        return best_act\n",
    "\n",
    "    def act(self, belief: Belief) -> Tuple[str, str]:\n",
    "        \"\"\"Deny wheat early, then kite with hoarded wheat.\"\"\"\n",
    "        me, tm = belief.self_state, belief.teammate_state\n",
    "        inv_w = me.inv.count(ITEM_WHEAT)\n",
    "        cap   = 10\n",
    "\n",
    "        # List wheat positions\n",
    "        wheat = [Pos(r, c)\n",
    "                 for r, row in enumerate(belief.grid)\n",
    "                 for c, v in enumerate(row) if v == TILE_WHEAT]\n",
    "\n",
    "        # 1) If bag not full, deny: chase the wheat closest to teammate\n",
    "        if inv_w < cap and wheat:\n",
    "            target = min(wheat, key=lambda p: p.adjacent(tm.pos))\n",
    "            if target == me.pos:\n",
    "                return (\"pick\", \"PICK\")\n",
    "            # step greedily toward target\n",
    "            dr, dc = target.r - me.pos.r, target.c - me.pos.c\n",
    "            if abs(dr) >= abs(dc) and dr != 0:\n",
    "                return (\"to deny\", \"MOVE_S\" if dr > 0 else \"MOVE_N\")\n",
    "            if dc != 0:\n",
    "                return (\"to deny\", \"MOVE_E\" if dc > 0 else \"MOVE_W\")\n",
    "            return (\"wait\", \"WAIT\")\n",
    "\n",
    "        # 2) Hoard mode: holding any wheat (or full) → kite away from both station and teammate\n",
    "        if inv_w >= 1:\n",
    "            H = len(belief.grid); W = len(belief.grid[0]) if H else 0\n",
    "            act = self._best_away_move((H, W), me.pos, tm.pos, belief.station)\n",
    "            return (\"hoard\", act)\n",
    "\n",
    "        # 3) No wheat visible and bag empty → idle or drift away from station/teammate\n",
    "        H = len(belief.grid); W = len(belief.grid[0]) if H else 0\n",
    "        act = self._best_away_move((H, W), me.pos, tm.pos, belief.station)\n",
    "        return (\"loiter\", act)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(3) ToM Policy**\n",
    "> ### TheoryOfMindPolicy: Learning to Trust or Go Solo\n",
    "> This policy wraps the cooperative policy with a simple **theory-of-mind trust model**:\n",
    ">\n",
    "> **Core idea**\n",
    "> - Maintains a scalar trust score `p_coop ∈ [0,1]` about the teammate.\n",
    "> - Updates `p_coop` every turn using **chat + last actions** as weak evidence.\n",
    "> - Switches between *cooperative* and *self-reliant* behavior based on that score.\n",
    ">\n",
    "> **Trust thresholds**\n",
    "> - **High trust (`p_coop ≥ 0.65`)**  \n",
    ">   → Delegate directly to `CooperativePolicy` (assume teammate is helpful).\n",
    "> - **Low trust (`p_coop ≤ ~0.35`)**  \n",
    ">   → Avoid relying on `GIVE`; try to collect enough wheat to craft alone.\n",
    "> - **In between**  \n",
    ">   → “Hedge”: collect wheat with deconfliction, but do not wait around for help.\n",
    ">\n",
    "> **Evidence used for updates**\n",
    "> - **Positive (more cooperative):**\n",
    ">   - `GIVE` when adjacent → strong boost.\n",
    ">   - Chat messages like “take”, “to you”, “ready” → small boost.\n",
    ">   - Moving toward the station while already holding enough wheat → small boost.\n",
    "> - **Negative (less cooperative):**\n",
    ">   - `DROP` away from station or kiting while holding wheat → strong penalty.\n",
    ">   - Standing adjacent with both holding wheat but no `GIVE` for several turns → gradual penalty.\n",
    ">   - Chasing wheat closer to *me* repeatedly (denial) → small penalty.\n",
    ">\n",
    "> **Decision flow in `act()`**\n",
    "> 1. Update `p_coop` using `_update_belief(...)`.\n",
    "> 2. If trust is high → behave like a pure cooperator.\n",
    "> 3. Else if combined wheat at station is enough → attempt team craft.\n",
    "> 4. Else if I alone have enough → go craft solo.\n",
    "> 5. Otherwise → collect wheat favoring tiles **close to me and far from teammate**, then fall back to staying near the station when no wheat is visible.\n",
    ">\n",
    "> As with other policies, the output is a pair  \n",
    "> **(short chat message, environment action)**, which makes the evolving trust behavior easy to inspect in logs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TheoryOfMindPolicy(BasePolicy):\n",
    "    \"\"\"\n",
    "    Theory-of-Mind (ToM) policy:\n",
    "    - Maintains a scalar trust belief p_coop in [0,1] about teammate.\n",
    "    - Updates p_coop based on chat and last intents (GIVE/DROP/movement patterns).\n",
    "    - High trust (p>=0.65): delegate behavior to CooperativePolicy.\n",
    "    - Low trust (p<=0.35): avoid sharing; aim to self-satisfy recipe.\n",
    "    - In between: hedge; collect while deconflicting, but do not rely on GIVE.\n",
    "\n",
    "    This class is the \"reasoning wrapper\" around CooperativePolicy, using\n",
    "    simple heuristics as weak Bayesian-style evidence updates.\n",
    "    \n",
    "    Evidence (weak Bayesian-style updates each turn):\n",
    "      + GIVE when adjacent (Chebyshev)                → strong COOP (+0.25)\n",
    "      + Chat hints {\"take\",\"to you\",\"ready\"}          → weak COOP (+0.10)\n",
    "      + Moving to station with >= need_w wheat        → weak COOP (+0.08)\n",
    "      + DROP away from station or kiting while holding→ strong NON-COOP (−0.25)\n",
    "      + Adjacent (both ≥1) but no GIVE over time      → NON-COOP (−0.06 per 2 stalls)\n",
    "      + Chasing wheat closest to me repeatedly        → weak NON-COOP (−0.04)\n",
    "    \"\"\"\n",
    "    def __init__(self, name: str):\n",
    "        super().__init__(name, Role.COOP)\n",
    "        self.p_coop: float = 0.5\n",
    "        self._coop_impl = CooperativePolicy(name)\n",
    "        self._last_tm_pos: Optional[Pos] = None\n",
    "        self._adjacency_stall: int = 0  # counts turns adjacent (both ≥1) without GIVE\n",
    "\n",
    "    def _clip(self, x: float) -> float:\n",
    "        \"\"\"Clamp trust to [0,1].\"\"\"\n",
    "        return max(0.0, min(1.0, x))\n",
    "\n",
    "    def _cheb_adjacent(self, a: Pos, b: Pos) -> bool:\n",
    "        \"\"\"Adjacent if max(|dr|,|dc|) ≤ 1 (includes diagonals & overlap).\"\"\"\n",
    "        return max(abs(a.r - b.r), abs(a.c - b.c)) <= 1\n",
    "\n",
    "    def _step_toward(self, a: Pos, b: Pos) -> str:\n",
    "        \"\"\"Same greedy movement as CooperativePolicy.\"\"\"\n",
    "        dr, dc = b.r - a.r, b.c - a.c\n",
    "        if abs(dr) >= abs(dc) and dr != 0: return \"MOVE_S\" if dr > 0 else \"MOVE_N\"\n",
    "        if dc != 0: return \"MOVE_E\" if dc > 0 else \"MOVE_W\"\n",
    "        return \"WAIT\"\n",
    "\n",
    "    def _update_belief(self, belief: Belief):\n",
    "        \"\"\"\n",
    "        Update scalar trust p_coop based on recent chat and teammate intents.\n",
    "\n",
    "        Positive evidence: GIVE, pro-social chat, going to station to craft.\n",
    "        Negative evidence: DROP / kiting, stalling adjacent without GIVE,\n",
    "        chasing wheat near me (denial).\n",
    "        \"\"\"\n",
    "        me, tm = belief.self_state, belief.teammate_state\n",
    "        last_tm_intent = belief.last_intents.get(tm.name, \"\")\n",
    "        need_w = belief.recipe.get(ITEM_WHEAT, 4)\n",
    "\n",
    "        # Chat evidence (weak coop)\n",
    "        if belief.chat_last:\n",
    "            for who, msg in belief.chat_last:\n",
    "                if who == tm.name:\n",
    "                    m = msg.lower()\n",
    "                    if any(k in m for k in [\"take\", \"to you\", \"ready\"]):\n",
    "                        self.p_coop = self._clip(self.p_coop + 0.10)\n",
    "\n",
    "        # Action / movement evidence\n",
    "        if last_tm_intent == \"GIVE\":\n",
    "            self.p_coop = self._clip(self.p_coop + 0.25)\n",
    "        elif last_tm_intent == \"DROP\":\n",
    "            self.p_coop = self._clip(self.p_coop - 0.25)\n",
    "        elif last_tm_intent in (\"MOVE_N\",\"MOVE_S\",\"MOVE_E\",\"MOVE_W\"):\n",
    "            if self._last_tm_pos is not None and tm.pos.adjacent(me.pos) < self._last_tm_pos.adjacent(me.pos):\n",
    "                self.p_coop = self._clip(self.p_coop - 0.04)\n",
    "\n",
    "        # Pro-social tendency: heading to craft with >= need_w\n",
    "        if tm.inv.count(ITEM_WHEAT) >= need_w and tm.pos.adjacent(belief.station) < me.pos.adjacent(belief.station):\n",
    "            self.p_coop = self._clip(self.p_coop + 0.08)\n",
    "\n",
    "        # Detect kiting/hoarding: holding wheat but increasing distance to station & not getting closer to me\n",
    "        if tm.inv.count(ITEM_WHEAT) >= 1 and self._last_tm_pos is not None:\n",
    "            if (tm.pos.adjacent(belief.station) > self._last_tm_pos.adjacent(belief.station)\n",
    "                and tm.pos.adjacent(me.pos) >= self._last_tm_pos.adjacent(me.pos)):\n",
    "                self.p_coop = self._clip(self.p_coop - 0.25)\n",
    "\n",
    "        # Adjacency stall penalty (Chebyshev): both have ≥1, adjacent, and no GIVE accumulating\n",
    "        if self._cheb_adjacent(me.pos, tm.pos) and me.inv.count(ITEM_WHEAT) >= 1 and tm.inv.count(ITEM_WHEAT) >= 1:\n",
    "            if last_tm_intent != \"GIVE\":\n",
    "                self._adjacency_stall += 1\n",
    "                if self._adjacency_stall % 2 == 0:\n",
    "                    self.p_coop = self._clip(self.p_coop - 0.06)\n",
    "        else:\n",
    "            self._adjacency_stall = 0\n",
    "\n",
    "        self._last_tm_pos = tm.pos\n",
    "\n",
    "    def act(self, belief: Belief) -> Tuple[str, str]:\n",
    "        \"\"\"Update trust, then choose behavior based on p_coop.\"\"\"\n",
    "        print('Trust in other agent:', self.p_coop)  # debug: inspect trust trajectory\n",
    "        self._update_belief(belief)\n",
    "\n",
    "        me, tm = belief.self_state, belief.teammate_state\n",
    "        inv = list(me.inv); inv_w = inv.count(ITEM_WHEAT)\n",
    "        tm_w = tm.inv.count(ITEM_WHEAT)\n",
    "        need_w = belief.recipe.get(ITEM_WHEAT, 4)\n",
    "        cap   = 10\n",
    "\n",
    "        # High trust → cooperative handoff (uses same Chebyshev GIVE rule in env step)\n",
    "        if self.p_coop >= 0.65:\n",
    "            return self._coop_impl.act(belief)\n",
    "\n",
    "        # If at station and (me+adjacent teammate) meet recipe → team-craft now\n",
    "        if me.pos == belief.station and self._cheb_adjacent(me.pos, tm.pos) and inv_w + tm_w >= need_w:\n",
    "            return (\"team craft\", \"CRAFT\")\n",
    "\n",
    "        # Solo craft if I already have enough\n",
    "        if inv_w >= need_w:\n",
    "            if me.pos == belief.station:\n",
    "                return (\"crafting\", \"CRAFT\")\n",
    "            return (\"to C\", self._step_toward(me.pos, belief.station))\n",
    "\n",
    "        # Low/uncertain trust → collect to reach need_w myself (deconflict with teammate)\n",
    "        wheat = [Pos(r,c) for r,row in enumerate(belief.grid) for c,v in enumerate(row) if v == TILE_WHEAT]\n",
    "        if wheat:\n",
    "            # Prefer wheat close to me and far from teammate\n",
    "            def score(p: Pos) -> Tuple[int, int]:\n",
    "                return (p.adjacent(me.pos), -p.adjacent(tm.pos))\n",
    "            target = min(wheat, key=score)\n",
    "\n",
    "            if target == me.pos:\n",
    "                # Pick if I still have space\n",
    "                if len(inv) < cap:\n",
    "                    return (\"pick\", \"PICK\")\n",
    "                # Full but below need_w → head to station (team craft or free slot via crafting later)\n",
    "                return (\"full→C\", self._step_toward(me.pos, belief.station))\n",
    "\n",
    "            # Move toward chosen wheat\n",
    "            return (\"to W\", self._step_toward(me.pos, target))\n",
    "\n",
    "        # Nothing visible → go to station; don't WAIT in low-trust\n",
    "        if me.pos == belief.station:\n",
    "            # If adjacent to tm and combined enough, attempt craft; else idle once\n",
    "            if self._cheb_adjacent(me.pos, tm.pos) and inv_w + tm_w >= need_w:\n",
    "                return (\"team craft\", \"CRAFT\")\n",
    "            return (\"wait\", \"WAIT\")\n",
    "        return (\"to C\", self._step_toward(me.pos, belief.station))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Visualization Building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Matplotlib viz ======\n",
    "def _mpl():\n",
    "    \"\"\"Lazy import guard for matplotlib so CLI can run headless.\"\"\"\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        import matplotlib.patches as patches\n",
    "        return plt, patches\n",
    "    except Exception:\n",
    "        return None, None\n",
    "\n",
    "def draw(ax, game: CoopGame, chat_line: str = \"\"):\n",
    "    \"\"\"\n",
    "    Simple 2D grid visualization of the current game state.\n",
    "\n",
    "    - Wheat tiles: squares\n",
    "    - Station: circle\n",
    "    - Agents: triangles labeled with initials\n",
    "    - Bottom text: most recent chat line\n",
    "    \"\"\"\n",
    "    plt, patches = _mpl()\n",
    "    if plt is None:\n",
    "        return\n",
    "    ax.clear()\n",
    "\n",
    "    n = game.world.size\n",
    "    ax.set_xlim(0, n); ax.set_ylim(0, n)\n",
    "    ax.set_aspect('equal'); ax.invert_yaxis()\n",
    "    ax.set_xticks(range(n+1)); ax.set_yticks(range(n+1))\n",
    "    ax.grid(True, linewidth=0.8)\n",
    "\n",
    "    # soft background\n",
    "    ax.add_patch(patches.Rectangle((0, 0), n, n, alpha=0.08, zorder=0))\n",
    "\n",
    "    # tiles\n",
    "    for r in range(n):\n",
    "        for c in range(n):\n",
    "            t = game.world.grid[r][c]\n",
    "            if t == TILE_WHEAT:\n",
    "                ax.add_patch(patches.Rectangle((c+0.15, r+0.15), 0.7, 0.7,\n",
    "                                               fill=False, linewidth=2, zorder=1))\n",
    "            elif t == TILE_STATION:\n",
    "                ax.add_patch(patches.Circle((c+0.5, r+0.5), 0.42, zorder=1))\n",
    "\n",
    "    # agents\n",
    "    for name, a in game.agents.items():\n",
    "        ax.add_patch(patches.RegularPolygon((a.pos.c+0.5, a.pos.r+0.5),\n",
    "                                            numVertices=3, radius=0.36, zorder=2))\n",
    "        # Lower the label: +0.34 (downwards on screen because y-axis is inverted)\n",
    "        ax.text(a.pos.c+0.5, a.pos.r+0.34, name[0], ha='center', va='center',\n",
    "                fontsize=10, zorder=3)\n",
    "\n",
    "    # title\n",
    "    ax.set_title(\n",
    "        f\"Turn {game.turn} | Crafted {game.crafted} | \"\n",
    "        f\"A:{game.agents['ALICE'].inv} B:{game.agents['BOB'].inv}\"\n",
    "    )\n",
    "\n",
    "    # chat line on axes coords (cleared with ax.clear())\n",
    "    if chat_line:\n",
    "        ax.text(0.5, -0.12, chat_line[:120], ha='center', va='top',\n",
    "                transform=ax.transAxes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Game Instantiation\n",
    "> ### Modes, Config, and Logging\n",
    "> - `Mode` selects **which pair of policies** we run for (`ALICE`, `BOB`):\n",
    ">   - `COOP`: both cooperative.\n",
    ">   - `ADV`: cooperator vs adversary.\n",
    ">   - `TOM_COOP`: ToM agent vs cooperator.\n",
    ">   - `TOM_ADV`: ToM agent vs adversary.\n",
    "> - `Config` stores the **episode setup**:\n",
    ">   number of steps, grid size, random seed, whether to show matplotlib viz, FPS, and which `Mode` to run.\n",
    "> - `StepLog` is a **per-turn record** (grid ASCII, chats, actions, inventories, crafted items) used for printing and analysis.\n",
    "> - `EpisodeResult` bundles the **full trajectory** (`logs`) plus the final `CoopGame` instance for downstream evaluation.\n",
    ">\n",
    "> ### Agent wrapper and roster\n",
    "> - `Agent` is a thin wrapper binding:\n",
    ">   - a **policy** (`CooperativePolicy`, `AdversarialPolicy`, or `TheoryOfMindPolicy`),\n",
    ">   - a capacity (inventory limit),\n",
    ">   - and a helper `policy_step()` that:\n",
    ">     - builds a `Belief` from a `GameState` snapshot,\n",
    ">     - calls `policy.act(...)`,\n",
    ">     - uppercases and validates the action,\n",
    ">     - and truncates the chat message.\n",
    "> - `build_agents(mode)` constructs the **ALICE/BOB roster** for the chosen `Mode`, wiring which policy each agent uses.\n",
    ">\n",
    "> ### Running an episode\n",
    "> - `run_episode(cfg)` executes one full game:\n",
    ">   1. Create `CoopGame` and build the agent roster from `cfg.mode`.\n",
    ">   2. Optionally set up matplotlib viz.\n",
    ">   3. For each turn:\n",
    ">      - snapshot the game,\n",
    ">      - query ALICE (with current state) and log her message,\n",
    ">      - snapshot again and query BOB (who sees ALICE’s new chat),\n",
    ">      - apply both actions via `game.step(intents)`,\n",
    ">      - append a `StepLog` entry and update the visualization.\n",
    ">      - stop early if the goal is reached (`game.is_done()`).\n",
    ">   4. Return an `EpisodeResult` with all logs and the final game state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mode(Enum):\n",
    "    \"\"\"CLI modes specifying which policies to run for ALICE/BOB.\"\"\"\n",
    "    COOP = \"coop\"\n",
    "    ADV = \"adv\"\n",
    "    TOM_COOP = \"tom_coop\"\n",
    "    TOM_ADV = \"tom_adv\"\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Config:\n",
    "    \"\"\"Episode configuration (size, duration, mode, viz).\"\"\"\n",
    "    steps: int = 80\n",
    "    size: int = 7\n",
    "    seed: int = 0\n",
    "    viz: bool = False\n",
    "    fps: float = 4.0\n",
    "    mode: Mode = Mode.COOP\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class StepLog:\n",
    "    \"\"\"Per-turn log used for printing / analysis / future evaluation scripts.\"\"\"\n",
    "    turn: int\n",
    "    grid_text: str\n",
    "    chats: List[Tuple[str,str]]\n",
    "    actions: Dict[str,str]\n",
    "    inventories: Dict[str,List[str]]\n",
    "    crafted: Dict[str,int]\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class EpisodeResult:\n",
    "    \"\"\"Final episode container (for analysis / tests).\"\"\"\n",
    "    logs: List['StepLog']\n",
    "    game: CoopGame\n",
    "\n",
    "class Agent:\n",
    "    \"\"\"\n",
    "    Thin wrapper that binds a policy instance to an environment-side agent.\n",
    "\n",
    "    Handles:\n",
    "    - building Belief from GameState\n",
    "    - enforcing action validity and message length\n",
    "    \"\"\"\n",
    "    def __init__(self, name: str, policy: BasePolicy, capacity: int = 4):  # was 2\n",
    "        self.name = name\n",
    "        self.policy = policy\n",
    "        self.capacity = capacity\n",
    "        \n",
    "    def policy_step(self, gs: GameState, me: AgentState, tm: AgentState, goal: str) -> Tuple[str,str]:\n",
    "        \"\"\"Construct Belief from snapshot and query underlying policy.\"\"\"\n",
    "        belief = Belief(\n",
    "            turn=gs.turn,\n",
    "            goal=goal,\n",
    "            recipe=RECIPE[goal],\n",
    "            station=gs.station,\n",
    "            grid=gs.grid,\n",
    "            self_state=me,\n",
    "            teammate_state=tm,\n",
    "            chat_last=gs.chat_log[-2:] if gs.chat_log else [],\n",
    "            last_intents=gs.last_intents,\n",
    "            inventory_capacity=self.capacity,\n",
    "        )\n",
    "        msg, act = self.policy.act(belief)\n",
    "        act = act.upper()\n",
    "        if act not in VALID_ACTIONS: act = \"WAIT\"\n",
    "        return (msg[:60], act)\n",
    "\n",
    "def build_agents(mode: Mode) -> Dict[str, Agent]:\n",
    "    \"\"\"\n",
    "    Build agent roster for the selected mode.\n",
    "\n",
    "    COOP: ALICE, BOB both cooperative.\n",
    "    ADV:  ALICE coop, BOB adversarial.\n",
    "    TOM_COOP: ALICE ToM, BOB cooperative.\n",
    "    TOM_ADV:  ALICE ToM, BOB adversarial.\n",
    "    \"\"\"\n",
    "    if mode == Mode.COOP:\n",
    "        return {\n",
    "            \"ALICE\": Agent(\"ALICE\", CooperativePolicy(\"ALICE\")),\n",
    "            \"BOB\":   Agent(\"BOB\",   CooperativePolicy(\"BOB\")),\n",
    "        }\n",
    "    elif mode == Mode.ADV:\n",
    "        # v2: B will become adversarial\n",
    "        return {\n",
    "            \"ALICE\": Agent(\"ALICE\", CooperativePolicy(\"ALICE\")),\n",
    "            \"BOB\":   Agent(\"BOB\",   AdversarialPolicy(\"BOB\")),\n",
    "        }\n",
    "    elif mode == Mode.TOM_COOP:\n",
    "        # v3: A will run ToM; B cooperative \n",
    "        return {\n",
    "            \"ALICE\": Agent(\"ALICE\", TheoryOfMindPolicy(\"ALICE\")),\n",
    "            \"BOB\":   Agent(\"BOB\",   CooperativePolicy(\"BOB\")),\n",
    "        }\n",
    "    elif mode == Mode.TOM_ADV:\n",
    "        # v4: A will run ToM; B adversarial\n",
    "        return {\n",
    "            \"ALICE\": Agent(\"ALICE\", TheoryOfMindPolicy(\"ALICE\")),\n",
    "            \"BOB\":   Agent(\"BOB\",   AdversarialPolicy(\"BOB\")),\n",
    "        }\n",
    "\n",
    "def run_episode(cfg: Config) -> EpisodeResult:\n",
    "    \"\"\"\n",
    "    Run a single episode under the given configuration.\n",
    "\n",
    "    Loop:\n",
    "    - snapshot game state\n",
    "    - query ALICE, then BOB (with updated chat log)\n",
    "    - apply actions in environment\n",
    "    - log state and optionally update matplotlib visualization\n",
    "    \"\"\"\n",
    "    game = CoopGame(size=cfg.size, seed=cfg.seed)\n",
    "    roster = build_agents(cfg.mode)\n",
    "    # Align env capacities with agent wrappers (currently unused by step()).\n",
    "    game.capacity = {name: roster[name].capacity for name in roster}\n",
    "\n",
    "    plt,_ = _mpl()\n",
    "    fig = None\n",
    "    ax  = None\n",
    "    if cfg.viz and plt is not None:\n",
    "        fig = plt.figure(figsize=(12,8))\n",
    "        ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "    logs: List[StepLog] = []\n",
    "    for _ in range(cfg.steps):\n",
    "        gs = game.snapshot()\n",
    "        a, b = gs.agents[\"ALICE\"], gs.agents[\"BOB\"]\n",
    "        # ALICE sees current state.\n",
    "        msgA, actA = roster[\"ALICE\"].policy_step(gs, a, b, game.goal); game.chat_log.append((\"ALICE\", msgA))\n",
    "        gs2 = game.snapshot()\n",
    "        # BOB sees updated chat log (includes ALICE's message).\n",
    "        msgB, actB = roster[\"BOB\"].policy_step(gs2, b, a, game.goal); game.chat_log.append((\"BOB\", msgB))\n",
    "        intents = {\"ALICE\": actA, \"BOB\": actB}\n",
    "        game.step(intents)\n",
    "\n",
    "        logs.append(StepLog(turn=game.turn,\n",
    "                            grid_text=game.render_text(),\n",
    "                            chats=game.chat_log[-2:],\n",
    "                            actions=intents,\n",
    "                            inventories={k: v.inv[:] for k,v in game.agents.items()},\n",
    "                            crafted=game.crafted.copy()))\n",
    "        if cfg.viz and plt is not None:\n",
    "            draw(ax, game)\n",
    "            chat = \" | \".join([f\"{w}: {m}\" for w, m in logs[-1].chats])\n",
    "            draw(ax, game, chat_line=chat)\n",
    "            plt.pause(max(1e-3, 1.0 / max(1e-6, cfg.fps)))\n",
    "        if game.is_done():\n",
    "            break\n",
    "\n",
    "    if cfg.viz and plt is not None:\n",
    "        plt.show(block=False)\n",
    "\n",
    "    return EpisodeResult(logs=logs, game=game)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Game Running**\n",
    "> ### Visualization Notes\n",
    "> - Inside this notebook, **we only display text-based results** (e.g., grid snapshots, logs).  \n",
    "> - Matplotlib’s real-time animation **cannot update inside the notebook**, even when `viz=True`.\n",
    "> - If you want **true real-time visualization** in a pop-up window (the same as running the `.py` script),  \n",
    "> - please run the following commands from your terminal:\n",
    "> ---\n",
    "> ### ▶️ Run 10 visualized episodes (batch scripts) with real-time visualization\n",
    "> ```bash\n",
    "> bash run_coop.sh\n",
    "> bash run_adv.sh\n",
    "> bash run_tom_coop.sh\n",
    "> bash run_tom_adv.sh\n",
    "> ```\n",
    "> Each script runs 10 episodes with visualization enabled.\n",
    "> ### ▶️ Run a single visualized episode with real-time visualization\n",
    "> ```bash\n",
    "> python coop2_modular.py --viz --mode coop\n",
    "> python coop2_modular.py --viz --mode adv\n",
    "> python coop2_modular.py --viz --mode tom_coop\n",
    "> python coop2_modular.py --viz --mode tom_adv\n",
    "> ```\n",
    "> These commands open a real-time matplotlib window showing the agents moving each turn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(1) COOP vs COOP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COOP vs COOP ===\n",
      "Crafted: {'BREAD': 1}\n",
      "Turns: 24\n",
      "Success: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "cfg = Config(\n",
    "    mode=Mode.COOP,\n",
    "    steps=60,\n",
    "    size=7,\n",
    "    seed=1,\n",
    "    viz=False\n",
    ")\n",
    "\n",
    "result = run_episode(cfg)\n",
    "\n",
    "print(\"=== COOP vs COOP ===\")\n",
    "print(\"Crafted:\", result.game.crafted)\n",
    "print(\"Turns:\", result.logs[-1].turn)\n",
    "print(\"Success:\", result.game.is_done())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(2) COOP vs ADV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COOP vs ADVERSARY ===\n",
      "Crafted: {'BREAD': 0}\n",
      "Turns: 60\n",
      "Success: False\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "cfg = Config(\n",
    "    mode=Mode.ADV,\n",
    "    steps=60,\n",
    "    size=7,\n",
    "    seed=2,\n",
    "    viz=False\n",
    ")\n",
    "\n",
    "result = run_episode(cfg)\n",
    "\n",
    "print(\"=== COOP vs ADVERSARY ===\")\n",
    "print(\"Crafted:\", result.game.crafted)\n",
    "print(\"Turns:\", result.logs[-1].turn)\n",
    "print(\"Success:\", result.game.is_done())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(3) ToM vs COOP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trust in other agent: 0.5\n",
      "Trust in other agent: 0.5\n",
      "Trust in other agent: 0.5\n",
      "Trust in other agent: 0.5\n",
      "Trust in other agent: 0.25\n",
      "Trust in other agent: 0.25\n",
      "Trust in other agent: 0.21\n",
      "Trust in other agent: 0.21\n",
      "Trust in other agent: 0.16999999999999998\n",
      "Trust in other agent: 0.16999999999999998\n",
      "Trust in other agent: 0.16999999999999998\n",
      "Trust in other agent: 0.23\n",
      "Trust in other agent: 0.29000000000000004\n",
      "Trust in other agent: 0.64\n",
      "Trust in other agent: 0.99\n",
      "Trust in other agent: 1.0\n",
      "Trust in other agent: 1.0\n",
      "Trust in other agent: 1.0\n",
      "Trust in other agent: 0.96\n",
      "=== ToM vs COOP ===\n",
      "Crafted: {'BREAD': 1}\n",
      "Turns: 19\n",
      "Success: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "cfg = Config(\n",
    "    mode=Mode.TOM_COOP,\n",
    "    steps=60,\n",
    "    size=7,\n",
    "    seed=3,\n",
    "    viz=False\n",
    ")\n",
    "\n",
    "result = run_episode(cfg)\n",
    "\n",
    "print(\"=== ToM vs COOP ===\")\n",
    "print(\"Crafted:\", result.game.crafted)\n",
    "print(\"Turns:\", result.logs[-1].turn)\n",
    "print(\"Success:\", result.game.is_done())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(4) ToM vs ADV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trust in other agent: 0.5\n",
      "Trust in other agent: 0.5\n",
      "Trust in other agent: 0.46\n",
      "Trust in other agent: 0.46\n",
      "Trust in other agent: 0.42000000000000004\n",
      "Trust in other agent: 0.38000000000000006\n",
      "Trust in other agent: 0.3400000000000001\n",
      "Trust in other agent: 0.3000000000000001\n",
      "Trust in other agent: 0.3000000000000001\n",
      "Trust in other agent: 0.2600000000000001\n",
      "Trust in other agent: 0.2200000000000001\n",
      "Trust in other agent: 0.1800000000000001\n",
      "Trust in other agent: 0.1800000000000001\n",
      "Trust in other agent: 0.1400000000000001\n",
      "Trust in other agent: 0.1400000000000001\n",
      "Trust in other agent: 0.10000000000000009\n",
      "Trust in other agent: 0.06000000000000009\n",
      "Trust in other agent: 0.020000000000000087\n",
      "Trust in other agent: 0.0\n",
      "Trust in other agent: 0.0\n",
      "Trust in other agent: 0.0\n",
      "Trust in other agent: 0.0\n",
      "Trust in other agent: 0.0\n",
      "Trust in other agent: 0.0\n",
      "=== ToM vs ADVERSARY ===\n",
      "Crafted: {'BREAD': 1}\n",
      "Turns: 24\n",
      "Success: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "cfg = Config(\n",
    "    mode=Mode.TOM_ADV,\n",
    "    steps=60,\n",
    "    size=7,\n",
    "    seed=4,\n",
    "    viz=False\n",
    ")\n",
    "\n",
    "result = run_episode(cfg)\n",
    "\n",
    "print(\"=== ToM vs ADVERSARY ===\")\n",
    "print(\"Crafted:\", result.game.crafted)\n",
    "print(\"Turns:\", result.logs[-1].turn)\n",
    "print(\"Success:\", result.game.is_done())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mindcraft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
